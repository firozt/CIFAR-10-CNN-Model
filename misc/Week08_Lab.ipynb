{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16914,"status":"ok","timestamp":1674527620294,"user":{"displayName":"Ioanna Ntinou","userId":"17583344364006415397"},"user_tz":0},"id":"SYeUl0GqTiPg","outputId":"1d19f7d3-6514-4386-8c0b-4479d5f48fd4"},"outputs":[],"source":["# # Setting up google drive \n","# from google.colab import drive\n","# drive.mount('/content/gdrive', force_remount=True)\n","# import sys\n","# sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKJRukyjTeTR"},"outputs":[],"source":["import my_utils as mu\n","import torch\n","from torch import nn"]},{"cell_type":"markdown","metadata":{"id":"cYjhmqsiXsHH"},"source":["# The Task\n","\n","* Our **Task** for this week is to implement LeNet.\n","* The Learning Outcome: Hands-on application of PyTorch's API for creating and training CNNs.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gh0thI17TeTU"},"source":["# LeNet\n","\n","* At a high level, LeNet (LeNet-5) consists of 2 parts:\n","    1. a convolutional encoder consisting of two convolutional layers; and\n","    2. a dense block consisting of three fully-connected layers;\n","<!-- \n","![Data flow in LeNet. The input is a handwritten digit, the output a probability over 10 possible outcomes.](img/lenet.svg)  -->\n","\n","<!-- ![Data flow in LeNet. The input is a handwritten digit, the output a probability over 10 possible outcomes.](https://drive.google.com/uc?export=view&id=18Kd-JNGeKp38qAVEuxEyYU7rjNudWdWA) -->   \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uUTBAukyTeTV"},"source":["# LeNet -- Convolutional Encoder\n","\n","* Each convolutional *block* consists of: \n","    * A convolutional layer.\n","    * A sigmoid activation function (ReLUs were discovered recently).\n","    * A subsequent average pooling operation (max pooling was discovered later).\n","* Each convolutional layer uses a $5\\times 5$ kernel.\n","* The first convolutional layer has 6 output channels, while the second has 16.\n","* Each $2\\times2$ pooling operation (stride 2) reduces dimensionality by a factor of $4$ via spatial downsampling.\n","* The convolutional block emits an output with shape given by (batch size, number of channels, height, width).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U1e7kHElTeTV"},"source":["# LeNet -- Dense Block\n","\n","* In order to pass the output from the convolutional block to the dense block, we must flatten each example in the minibatch.\n","* In other words, we take the four-dimensional input and transform it into the two-dimensional input expected by fully-connected layers:\n","    * the two-dimensional representation that we desire uses the first dimension to index examples in the minibatch\n","    * the second to give the flat vector representation of each example.\n","* LeNet's dense block has three fully-connected layers, with 120, 84, and 10 outputs, respectively.\n","    * Because we are still performing classification, the 10-dimensional output layer corresponds to the number of possible output classes."]},{"cell_type":"markdown","metadata":{"id":"6fWxaKgJTeTW"},"source":["# Compressed LeNet Representation \n","\n","\n","<!-- ![Compressed notation for LeNet-5.](img/lenet-vert.svg) -->\n","\n"," ![Compressed notation for LeNet-5.](https://drive.google.com/uc?export=view&id=1sL0P0_DwSU8vSOvcoV6GKkwwokyuKysS) "]},{"cell_type":"markdown","metadata":{"id":"ZuGxje7cTeTW"},"source":["# Concise Implementation of LeNet\n","\n","* Goal: use high-level APIs of PyTorch for implementing LeNet for classification. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9fJJAC9TeTW"},"outputs":[],"source":["# Read training and test data\n","batch_size = 256\n","train_iter, test_iter = mu.load_data_fashion_mnist(batch_size)\n","type(train_iter)"]},{"cell_type":"markdown","metadata":{"id":"EknCtScjTeTX"},"source":["# Defining the Model\n","\n","* We will modify the code from MLP\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzstJPBqTeTX"},"outputs":[],"source":["class LeNet(torch.nn.Module):\n","    def __init__(self, num_inputs, num_outputs):\n","        super(LeNet, self).__init__()\n","        self.num_inputs = num_inputs\n","        self.num_outputs = num_outputs\n","        self.conv1 = nn.Conv2d(in_channels=num_inputs, out_channels=6, kernel_size=5, padding=2)\n","        self.relu = nn.ReLU()\n","        self.p1 = nn.AvgPool2d(kernel_size=2,stride=2)\n","        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16, kernel_size=5)\n","        self.p2 = nn.AvgPool2d(kernel_size=2,stride=2)\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(in_features=400,out_features=120)\n","        self.fc2 = nn.Linear(in_features=120, out_features=84)\n","        self.fc3 = nn.Linear(in_features=84,out_features=10)\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.relu(out)\n","        out = self.p1(out)\n","        out = self.conv2(out)\n","        out = self.relu(out)\n","        out = self.p2(out)\n","        out = self.flatten(out)\n","        out = self.fc1(out)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.relu(out)\n","        out = self.fc3(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLQCSd34TeTX"},"outputs":[],"source":["def init_weights(m):\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d: # by checking thr type we can init different layers in different ways\n","        torch.nn.init.xavier_uniform_(m.weight)          \n","\n","num_outputs = 10\n","model = LeNet(num_inputs=1, num_outputs=10)\n","\n","model.apply(init_weights);\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"3vwPW1iETeTY"},"source":["# Loss and Optimization Algorithm\n","* As in Softmax Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRRadXXxTeTY"},"outputs":[],"source":["loss = nn.CrossEntropyLoss()\n","lr = 0.9\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"ULuAOHDXTeTY"},"source":["# Training\n","\n","* Use `my_utils.train_ch3` as in Softmax Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJr4qkTJTeTY","scrolled":false},"outputs":[],"source":["num_epochs = 20\n","mu.train_ch3(model, train_iter, test_iter, loss, num_epochs, optimizer)"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
